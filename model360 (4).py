# -*- coding: utf-8 -*-
"""360Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gRV20LcnGyUrd-F_sDKlaAeF2m7ExMku
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
from timm import create_model  # For SEResNeXt50
from resnest.torch import resnest101  # Import ResNeSt-101
from pretrainedmodels import se_resnext101_32x4d  # Import SE-ResNeXt-101

class EffNetB0(nn.Module):
    def __init__(self):
        super(EffNetB0, self).__init__()
        self.name = "EffNetB0"

        # CNN for image processing
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        self.cnn = model.features

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),  # Added BatchNorm
            nn.SiLU(),  # Swish activation
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),  # Added BatchNorm
            nn.SiLU(),  # Swish activation
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(1280 + 128, 7)  # Combined features -> single output
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification
        output = self.fc(combined_features)
        return output

class EffNetB1(nn.Module):
    def __init__(self):
        super(EffNetB1, self).__init__()
        self.name = "EffNetB1"

        # CNN for image processing
        model = models.efficientnet_b1(weights='IMAGENET1K_V1')
        self.cnn = model.features  # Use the EfficientNet-B1 feature extractor

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(1280 + 128, 7)
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output

class EffNetB2(nn.Module):
    def __init__(self):
        super(EffNetB2, self).__init__()
        self.name = "EffNetB2"

        # CNN for image processing
        model = models.efficientnet_b2(weights='IMAGENET1K_V1')
        self.cnn = model.features

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(1408 + 128, 7)  # Combined features -> single output
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output

class EffNetB3(nn.Module):
    def __init__(self):
        super(EffNetB3, self).__init__()
        self.name = "EffNetB3"

        # CNN for image processing
        model = models.efficientnet_b3(weights='IMAGENET1K_V1')
        self.cnn = model.features

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(1664, 7)  # Combined features -> single output
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output

class ResNet18Model(nn.Module):
    def __init__(self):
        super(ResNet18Model, self).__init__()
        self.name = "ResNet18"

        # CNN for image processing (ResNet18 backbone)
        model = models.resnet18(weights='IMAGENET1K_V1')
        # Remove the final fully connected layer and pooling (Remove Classification Layers)
        self.cnn = nn.Sequential(*list(model.children())[:-2])

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512 + 128, 7)
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1)) # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification
        output = self.fc(combined_features)
        return output

class SEResNeXt50(nn.Module):
    def __init__(self):
        super(SEResNeXt50, self).__init__()
        self.name = "SEResNeXt50"

        # CNN for image processing (SEResNeXt-50 backbone)
        model = create_model('seresnext50_32x4d', pretrained=True)  # Load SEResNeXt-50
        self.cnn = nn.Sequential(*list(model.children())[:-2])  # Remove classification layers

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(2048 + 128, 7)
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output

class ResNeSt101Model(nn.Module):
    def __init__(self):
        super(ResNeSt101Model, self).__init__()
        self.name = "ResNeSt101"

        # CNN for image processing (ResNeSt-101 backbone)
        model = create_model('resnest101e', pretrained=True)
        self.cnn = nn.Sequential(*list(model.children())[:-2])

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(2048 + 128, 7)
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output

class SEResNeXt101Model(nn.Module):
    def __init__(self):
        super(SEResNeXt101Model, self).__init__()
        self.name = "SEResNeXt101"

        # CNN for image processing (SE-ResNeXt-101 backbone)
        model = create_model('seresnext101_32x4d', pretrained=True)  # Load SEResNeXt-101
        self.cnn = nn.Sequential(*list(model.children())[:-2])  # Remove classification layer

        # ANN for metadata processing
        self.ann = nn.Sequential(
            nn.Linear(9, 512),
            nn.BatchNorm1d(512),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128),
            nn.SiLU(),
        )

        # Final classification layer
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(2048 + 128, 7)  
        )

    def forward(self, image, metadata):
        # Process image through CNN
        cnn_features = self.cnn(image)
        cnn_features = F.adaptive_avg_pool2d(cnn_features, (1, 1))  # Global Average Pooling
        cnn_features = cnn_features.view(cnn_features.size(0), -1)  # Flatten

        # Process metadata through ANN
        ann_features = self.ann(metadata)

        # Combine features from both image and metadata
        combined_features = torch.cat((cnn_features, ann_features), dim=1)

        # Final classification through fully connected layers
        output = self.fc(combined_features)
        return output